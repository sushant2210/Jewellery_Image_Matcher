#!/usr/bin/env python3
"""
Streamlit app for jewelry similarity search using trained DINOv2 model
"""

import streamlit as st
import torch
import torch.nn as nn
import numpy as np
from PIL import Image
import json
import os
from torchvision import transforms
import plotly.express as px
import pandas as pd

# Set page config
st.set_page_config(
    page_title="Jewelry Similarity Search",
    page_icon="üíç",
    layout="wide",
    initial_sidebar_state="expanded"
)

class L2Norm(nn.Module):
    def __init__(self, eps=1e-8):
        super().__init__()
        self.eps = eps
        
    def forward(self, x):
        return torch.nn.functional.normalize(x, p=2, dim=1, eps=self.eps)

class JewelryDINOv2(nn.Module):
    def __init__(self, emb_dim=256):
        super().__init__()
        # Load pretrained DINOv2 ViT-L/14
        self.backbone = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitl14')
        
        # FREEZE the backbone
        for param in self.backbone.parameters():
            param.requires_grad = False
            
        # Projection head
        backbone_dim = 1024
        self.projection = nn.Sequential(
            nn.Linear(backbone_dim, 512),
            nn.ReLU(inplace=True),
            nn.BatchNorm1d(512),
            nn.Dropout(0.15),
            nn.Linear(512, emb_dim),
            L2Norm()
        )
        
    def forward(self, x):
        with torch.no_grad():
            features = self.backbone(x)
            
        if isinstance(features, dict):
            features = features.get('x_norm_clstoken', features.get('cls_token', features))
        if features.dim() == 3:
            features = features[:, 0, :]
            
        embeddings = self.projection(features)
        return embeddings

@st.cache_resource
def load_model_and_embeddings():
    """Load the trained model and precomputed embeddings"""
    
    model_dir = "jewelry_model"
    
    # Check if all required files exist
    required_files = [
        "best_model.pth",
        "embeddings.npy", 
        "labels.npy",
        "filenames.txt",
        "class_mappings.json"
    ]
    
    missing_files = []
    for file in required_files:
        if not os.path.exists(os.path.join(model_dir, file)):
            missing_files.append(file)
    
    if missing_files:
        st.error(f"Missing files in {model_dir}: {missing_files}")
        st.stop()
    
    # Load model
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    checkpoint = torch.load(os.path.join(model_dir, "best_model.pth"), 
                           map_location=device, weights_only=False)
    
    model = JewelryDINOv2(emb_dim=256).to(device)
    model.load_state_dict(checkpoint['model_state_dict'])
    model.eval()
    
    # Load precomputed embeddings
    embeddings = np.load(os.path.join(model_dir, "embeddings.npy"))
    labels = np.load(os.path.join(model_dir, "labels.npy"))
    
    with open(os.path.join(model_dir, "filenames.txt"), 'r') as f:
        filenames = [line.strip() for line in f.readlines()]
    
    with open(os.path.join(model_dir, "class_mappings.json"), 'r') as f:
        class_info = json.load(f)
    
    return model, embeddings, labels, filenames, class_info, device

def get_transform():
    """Get image preprocessing transform"""
    return transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))
    ])

def find_similar_jewelry(query_image, model, embeddings, labels, filenames, class_info, device, top_k=5):
    """Find similar jewelry pieces"""
    
    transform = get_transform()
    
    # Preprocess query image
    if query_image.mode != 'RGB':
        query_image = query_image.convert('RGB')
    
    query_tensor = transform(query_image).unsqueeze(0).to(device)
    
    # Get query embedding
    with torch.no_grad():
        query_embedding = model(query_tensor).cpu().numpy()
    
    # Compute similarities
    similarities = np.dot(embeddings, query_embedding.T).flatten()
    
    # Get top-k most similar
    top_indices = np.argsort(similarities)[::-1][:top_k]
    
    results = []
    for idx in top_indices:
        similarity_score = similarities[idx]
        filename = filenames[idx]
        label = labels[idx]
        class_name = class_info['idx_to_class'][str(label)]
        
        results.append({
            'filename': filename,
            'similarity': float(similarity_score),
            'class': class_name,
            'class_full': get_full_class_name(class_name)
        })
    
    return results

def get_full_class_name(class_abbrev):
    """Convert abbreviations to full names"""
    class_names = {
        'BB': 'Bajuband',
        'BH': 'Brooch', 
        'BR': 'Bracelet',
        'CK': 'Cufflinks',
        'CN': 'Chain',
        'DH': 'Silver Cz Bag',
        'EC': 'Earring Chain',
        'ER': 'Earring',
        'HO': 'Hair Ornaments',
        'HP': 'Haath Phool',
        'KB': 'Kurta Button',
        'KP': 'Kamar Patta',
        'LG': 'Bangle',
        'LO': 'Layout',
        'MF': 'Motif',
        'NA': 'Nath',
        'NK': 'Necklace', 
        'NP': 'Nosepin',
        'PD': 'Pendant',
        'PH': 'Peg Head',
        'RG': 'Ring',
        'TI': 'Tiara',
        'TK': 'Tika',
        'TM': 'Tanmaniya'
    }
    return class_names.get(class_abbrev, class_abbrev)

def display_image_with_info(image_path, similarity, class_name, class_full):
    """Display image with information"""
    try:
        # Construct full path
        full_path = os.path.join("Pictures/3D", image_path)
        
        if os.path.exists(full_path):
            img = Image.open(full_path)
            st.image(img, use_column_width=True)
        else:
            st.error(f"Image not found: {full_path}")
            
        st.write(f"**Similarity:** {similarity:.3f}")
        st.write(f"**Category:** {class_full} ({class_name})")
        st.write(f"**File:** {os.path.basename(image_path)}")
        
    except Exception as e:
        st.error(f"Error loading image: {e}")

def main():
    st.title("üíç Jewelry Similarity Search")
    st.markdown("Upload a jewelry image to find similar pieces in the database")
    
    # Load model and data
    with st.spinner("Loading model and embeddings..."):
        model, embeddings, labels, filenames, class_info, device = load_model_and_embeddings()
    
    # Sidebar info
    st.sidebar.header("üìä Database Info")
    st.sidebar.write(f"**Total Images:** {len(embeddings):,}")
    st.sidebar.write(f"**Categories:** {len(class_info['class_to_idx'])}")
    
    # Try to get model performance, fallback if not available
    try:
        accuracy = class_info['model_performance'][1]
        st.sidebar.write(f"**Model Accuracy:** {accuracy:.1%}")
    except KeyError:
        st.sidebar.write(f"**Model Accuracy:** 96.9%")  # Your known accuracy
    
    # Show category distribution
    unique_labels, counts = np.unique(labels, return_counts=True)
    df_stats = pd.DataFrame({
        'Category': [get_full_class_name(class_info['idx_to_class'][str(l)]) for l in unique_labels],
        'Count': counts
    })
    
    with st.sidebar.expander("üìà Category Distribution"):
        fig = px.bar(df_stats, x='Count', y='Category', orientation='h',
                     title="Images per Category")
        st.plotly_chart(fig, use_container_width=True)
    
    # Main interface
    col1, col2 = st.columns([1, 2])
    
    with col1:
        st.header("üîç Search")
        
        # File upload
        uploaded_file = st.file_uploader(
            "Choose a jewelry image...",
            type=['jpg', 'jpeg', 'png', 'bmp', 'tiff'],
            help="Upload an image of jewelry to find similar pieces"
        )
        
        # Number of results slider
        num_results = st.slider(
            "Number of similar images to show:",
            min_value=1,
            max_value=20,
            value=5,
            help="How many similar jewelry pieces to display"
        )
        
        if uploaded_file is not None:
            # Display uploaded image
            query_image = Image.open(uploaded_file)
            st.image(query_image, caption="Uploaded Image", use_column_width=True)
            
            # Search button
            if st.button("üîé Find Similar Jewelry", type="primary"):
                with st.spinner("Searching for similar jewelry..."):
                    results = find_similar_jewelry(
                        query_image, model, embeddings, labels, 
                        filenames, class_info, device, top_k=num_results
                    )
                
                # Store results in session state
                st.session_state.search_results = results
    
    with col2:
        st.header("‚ú® Similar Jewelry")
        
        # Display results
        if 'search_results' in st.session_state and st.session_state.search_results:
            results = st.session_state.search_results
            
            # Create columns for results
            if len(results) <= 3:
                cols = st.columns(len(results))
            else:
                # Create multiple rows
                for i in range(0, len(results), 3):
                    cols = st.columns(3)
                    for j, col in enumerate(cols):
                        if i + j < len(results):
                            result = results[i + j]
                            with col:
                                st.markdown(f"### #{i+j+1}")
                                display_image_with_info(
                                    result['filename'],
                                    result['similarity'], 
                                    result['class'],
                                    result['class_full']
                                )
                                st.markdown("---")
            
            # Summary statistics
            st.subheader("üìà Search Results Summary")
            categories = [r['class_full'] for r in results]
            similarities = [r['similarity'] for r in results]
            
            col_a, col_b = st.columns(2)
            with col_a:
                st.metric("Average Similarity", f"{np.mean(similarities):.3f}")
                st.metric("Best Match", f"{max(similarities):.3f}")
            
            with col_b:
                unique_categories = len(set(categories))
                st.metric("Categories Found", unique_categories)
                st.metric("Total Results", len(results))
                
        else:
            st.info("üëÜ Upload an image above to start searching!")
            
            # Show sample categories
            st.subheader("üè∑Ô∏è Available Categories")
            category_names = [get_full_class_name(abbrev) for abbrev in class_info['class_to_idx'].keys()]
            
            # Display in columns
            for i in range(0, len(category_names), 3):
                cols = st.columns(3)
                for j, col in enumerate(cols):
                    if i + j < len(category_names):
                        col.write(f"‚Ä¢ {category_names[i + j]}")

    # Footer
    st.markdown("---")
    st.markdown("**Powered by DINOv2 + Custom Jewelry Dataset** | Built with Streamlit")

if __name__ == "__main__":
    main()